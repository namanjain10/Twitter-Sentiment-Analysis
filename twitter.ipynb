{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv',error_bad_lines = False, encoding = \"ISO-8859-1\")\n",
    "\n",
    "with open('acronym_dict.csv', 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    acronym = dict(reader)\n",
    "\n",
    "with open('emoticon.csv', 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    emot = dict(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (0,ds.shape[0]) :\n",
    "    k = ds[i][2].split()\n",
    "    \n",
    "    for j in range (len(k)) :\n",
    "        if 'https' in k[j] or 'http' in k[j] or 'fttp' in k[j] :\n",
    "            k[j] = '|H|'\n",
    "            \n",
    "        if len(k[j]) > 1 and k[j][0] == '@' and k[j][1].isalpha() :\n",
    "            k[j] = '|N|'\n",
    "            \n",
    "        if len(k[j]) > 1 and k[j][0] == '#' and k[j][1].isalpha() :\n",
    "            k[j] = '|T|'\n",
    "            \n",
    "        count = 0\n",
    "       \n",
    "        ix = 1\n",
    "\n",
    "        while ix<len(k[j]):\n",
    "\n",
    "            if(k[j][ix] == k[j][ix-1]):\n",
    "                count = count + 1    \n",
    "\n",
    "                if(count > 2):\n",
    "                    k[j] = k[j][0:ix] + k[j][ix+1:len(k[j])]\n",
    "                    ix = ix - 1\n",
    "\n",
    "            else:\n",
    "                count = 0\n",
    "\n",
    "            ix+=1\n",
    "            \n",
    "        if k[j] in acronym:\n",
    "            k[j] = acronym[k[j]]\n",
    "            \n",
    "        if k[j] in emot:\n",
    "            k[j] = emot[k[j]]\n",
    "            \n",
    "    ds[i][2] = ' '.join(k)\n",
    "    ds[i][2] = re.sub('[^A-Za-z|]',' ',ds[i][2]).lower().split()\n",
    "    \n",
    "sent =[]\n",
    "\n",
    "for i in range (0,ds.shape[0]) :\n",
    "    sent.append(ds[i][2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ndim = 220\n",
    "tweet_w2v = Word2Vec(sent, size=ndim, window=10, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)\n",
    "matrix = vectorizer.fit_transform([x for x in sent])\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "emb = []\n",
    "\n",
    "for i in range(len(sent)):\n",
    "    \n",
    "    vec = np.zeros(ndim)\n",
    "    count = 0\n",
    "    \n",
    "    for word in sent[i]:\n",
    "        try:\n",
    "            vec += tweet_w2v[word] * tfidf[word]  \n",
    "            count += 1.\n",
    "        except : \n",
    "            continue\n",
    "            \n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "\n",
    "    emb.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# emb = []\n",
    "# for i in range (0, len(sent)) :\n",
    "#     temp = []\n",
    "#     for word in sent[i] :\n",
    "#         try :\n",
    "#             temp.append(tweet_w2v[word])\n",
    "#         except :\n",
    "#             pass\n",
    "    \n",
    "#     emb.append(temp)\n",
    "    \n",
    "label = []\n",
    "\n",
    "for i in range (ds.shape[0]) :\n",
    "    label.append(ds[i][1])\n",
    "    \n",
    "train_vecs_w2v = scale(np.array(emb)) #np.array(emb)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_vecs_w2v, label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 128)               28288     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 38,657\n",
      "Trainable params: 38,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(ndim,)))\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adagrad', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79991 samples, validate on 19998 samples\n",
      "Epoch 1/20\n",
      "79991/79991 [==============================] - 5s 58us/step - loss: 0.5476 - acc: 0.7179 - val_loss: 0.5239 - val_acc: 0.7347\n",
      "Epoch 2/20\n",
      "79991/79991 [==============================] - 4s 56us/step - loss: 0.5264 - acc: 0.7339 - val_loss: 0.5184 - val_acc: 0.7392\n",
      "Epoch 3/20\n",
      "79991/79991 [==============================] - 5s 65us/step - loss: 0.5201 - acc: 0.7391 - val_loss: 0.5152 - val_acc: 0.7394\n",
      "Epoch 4/20\n",
      "79991/79991 [==============================] - 8s 97us/step - loss: 0.5142 - acc: 0.7411 - val_loss: 0.5138 - val_acc: 0.7421\n",
      "Epoch 5/20\n",
      "79991/79991 [==============================] - 6s 70us/step - loss: 0.5109 - acc: 0.7452 - val_loss: 0.5116 - val_acc: 0.7430\n",
      "Epoch 6/20\n",
      "79991/79991 [==============================] - 6s 79us/step - loss: 0.5086 - acc: 0.7454 - val_loss: 0.5104 - val_acc: 0.7430\n",
      "Epoch 7/20\n",
      "79991/79991 [==============================] - 5s 62us/step - loss: 0.5050 - acc: 0.7486 - val_loss: 0.5107 - val_acc: 0.7447\n",
      "Epoch 8/20\n",
      "79991/79991 [==============================] - 5s 62us/step - loss: 0.5032 - acc: 0.7494 - val_loss: 0.5100 - val_acc: 0.7444\n",
      "Epoch 9/20\n",
      "79991/79991 [==============================] - 5s 67us/step - loss: 0.5003 - acc: 0.7505 - val_loss: 0.5094 - val_acc: 0.7443\n",
      "Epoch 10/20\n",
      "79991/79991 [==============================] - 5s 57us/step - loss: 0.4989 - acc: 0.7520 - val_loss: 0.5100 - val_acc: 0.7449\n",
      "Epoch 11/20\n",
      "79991/79991 [==============================] - 5s 60us/step - loss: 0.4959 - acc: 0.7530 - val_loss: 0.5114 - val_acc: 0.7459\n",
      "Epoch 12/20\n",
      "79991/79991 [==============================] - 5s 63us/step - loss: 0.4955 - acc: 0.7545 - val_loss: 0.5086 - val_acc: 0.7457\n",
      "Epoch 13/20\n",
      "79991/79991 [==============================] - 6s 70us/step - loss: 0.4929 - acc: 0.7557 - val_loss: 0.5097 - val_acc: 0.7455\n",
      "Epoch 14/20\n",
      "79991/79991 [==============================] - 5s 64us/step - loss: 0.4925 - acc: 0.7564 - val_loss: 0.5095 - val_acc: 0.7470\n",
      "Epoch 15/20\n",
      "79991/79991 [==============================] - 5s 61us/step - loss: 0.4908 - acc: 0.7576 - val_loss: 0.5082 - val_acc: 0.7475\n",
      "Epoch 16/20\n",
      "79991/79991 [==============================] - 5s 59us/step - loss: 0.4891 - acc: 0.7578 - val_loss: 0.5090 - val_acc: 0.7454\n",
      "Epoch 17/20\n",
      "79991/79991 [==============================] - 5s 66us/step - loss: 0.4883 - acc: 0.7580 - val_loss: 0.5078 - val_acc: 0.7473\n",
      "Epoch 18/20\n",
      "79991/79991 [==============================] - 5s 60us/step - loss: 0.4873 - acc: 0.7597 - val_loss: 0.5087 - val_acc: 0.7464\n",
      "Epoch 19/20\n",
      "79991/79991 [==============================] - 5s 69us/step - loss: 0.4864 - acc: 0.7589 - val_loss: 0.5085 - val_acc: 0.7461\n",
      "Epoch 20/20\n",
      "79991/79991 [==============================] - 5s 58us/step - loss: 0.4851 - acc: 0.7608 - val_loss: 0.5088 - val_acc: 0.7469\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = model.predict(x_test)\n",
    "\n",
    "for i in range (len(w)) :\n",
    "    if w[i] < 0.5 :\n",
    "        w[i] = 0\n",
    "    \n",
    "    else :\n",
    "        w[i] = 1  \n",
    "        \n",
    "w = w.reshape(w.shape[0],)\n",
    "r = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.74752475247524752,\n",
       " (0.76987012987012982, 0.78808827439510765, 0.77887268427276302, None))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(r, w), precision_recall_fscore_support(r, w, average='binary')    # precision recall fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
